{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 15:46:51.269477  8284 deprecation.py:506] From C:\\Users\\roli\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0806 15:46:51.591477  8284 deprecation.py:323] From C:\\Users\\roli\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17462 samples, validate on 7484 samples\n",
      "Epoch 1/10\n",
      "17462/17462 [==============================] - 1118s 64ms/sample - loss: 0.6625 - acc: 0.6044 - val_loss: 0.6045 - val_acc: 0.6729\n",
      "Epoch 2/10\n",
      "17462/17462 [==============================] - 1160s 66ms/sample - loss: 0.5960 - acc: 0.6846 - val_loss: 0.5747 - val_acc: 0.6979\n",
      "Epoch 3/10\n",
      "17462/17462 [==============================] - 1197s 69ms/sample - loss: 0.5587 - acc: 0.7141 - val_loss: 0.5544 - val_acc: 0.7282\n",
      "Epoch 4/10\n",
      "17462/17462 [==============================] - 1220s 70ms/sample - loss: 0.5269 - acc: 0.7436 - val_loss: 0.5611 - val_acc: 0.7137\n",
      "Epoch 5/10\n",
      "17462/17462 [==============================] - 1141s 65ms/sample - loss: 0.5036 - acc: 0.7555 - val_loss: 0.5082 - val_acc: 0.7531\n",
      "Epoch 6/10\n",
      "17462/17462 [==============================] - 1129s 65ms/sample - loss: 0.4853 - acc: 0.7684 - val_loss: 0.5108 - val_acc: 0.7545\n",
      "Epoch 7/10\n",
      "17462/17462 [==============================] - 1132s 65ms/sample - loss: 0.4617 - acc: 0.7829 - val_loss: 0.4885 - val_acc: 0.7658\n",
      "Epoch 8/10\n",
      "17462/17462 [==============================] - 1127s 65ms/sample - loss: 0.4460 - acc: 0.7925 - val_loss: 0.4990 - val_acc: 0.7628\n",
      "Epoch 9/10\n",
      "17462/17462 [==============================] - 1121s 64ms/sample - loss: 0.4300 - acc: 0.7995 - val_loss: 0.4926 - val_acc: 0.7667\n",
      "Epoch 10/10\n",
      "17462/17462 [==============================] - 1122s 64ms/sample - loss: 0.4135 - acc: 0.8096 - val_loss: 0.5176 - val_acc: 0.7590\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14c75780>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import pickle\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, batch_size=32, epochs=10, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
